###########
# Set up all keywords necessary to run this code - WE SHOULD ADD PIXEL SCALE AND MODIFY THE CODES IN CASE WE WANT TO RUN THIS ON 450 DATA - THIS WILL REQUIRE EDITING THE HARD CODED VALUES OF ALL THE TC PROGRAMS WE IMPORT!!!!
###########

def run_TC_pipeline(dirname,kern_name,param_file,beam_fwhm=14.5,crop_radius=1200,crop_method='CIRCLE',minpeak=0.2,maxrad=30.0,maxsep=10.0,cutoff=4,units='mjya2',wave=850):

  from TCGaussclumpsFunctions import run_gaussclumps,get_noise
  from TCOffsetFunctions_20160624 import source_match,cull_matches
  from TCPrepFunctions import crop_image,smooth_image,unitconv_image,prepare_image
  import time
  import os
  import datetime
  import subprocess
  import pdb
  import numpy as np
  import scipy.spatial.distance as ssd
  import astropy.io.fits as apfits
  import math
  import logging
  
  ###########
  ###########
  
  # KEYWORD DESCRIPTIONS
  
  #dirname     = directory with all the SDF files you'd like to generate GaussClumps catalogues for and compare
  #kern_name   = path to kernal which will be used to smooth the data before GaussClumps is run (including file name)
  #param_file  = path to GaussClumps parameter file (including file name)
  #beam_fwhm   = FWHM of the JCMT beam
  #param_file  = The parameter file given to GaussClumps (full path)
  #crop_radius = The radius at which to crop the edges of the maps to avoid areas with high noise
  #crop_method = The cropping method - this should always be CIRCLE
  #minpeak     = The minimum brightness of a source to consider matching it - !!! Jy per beam only !!! regardless of the input map units
  #maxrad      = The maximum effective radius of a source to consider matching it in arcseconds
  #maxsep      = The maximum allowed separation between two sources to initially match them (in arcseconds)
  #cutoff      = The refined maximum allowed separation between two sources to cull the sample to robust sources only (in arcseconds)  
  #units       = This can be either: 'mjya2', 'pw', or 'jybm'
  #wave        = Specify whether this is 450 or 850 microns
  
  ###########
  ###########
  ###########
  
  ###############
  # STEP 0 - Record the date and start the time to see how long the code takes to run 
  ###############

  
  today = datetime.date.today()
  mylist = []
  mylist.append(today)
  date=mylist[0] # print the date object, not the container ;-)

  initial_time=time.time()

  ###############
  # STEP 1 - Get the sdf files
  ###############

  #Change the working directory and Select all the fits files in the given directory:
  os.chdir(dirname)
  img_names=[]
  for file in sorted(os.listdir('.')):
      if file.endswith(".sdf"):
          img_names.append(str(file))

  # Begin Program Log
  logging.basicConfig(filename='TCpipeline'+str(date)+'.log',format='%(asctime)s  %(levelname)s:%(message)s',level=logging.DEBUG)
  logging.info(' TC-pipeline Log File: '+str(date)+'\n')
  logging.info(' Keywords: run_TC_pipeline('+dirname+','+kern_name+','+param_file+',beam_fwhm='+str(beam_fwhm)+',crop_radius='+str(crop_radius)+',crop_method='+crop_method+',minpeak='+str(minpeak)+',maxrad='+str(maxrad)+',maxsep='+str(maxsep)+',units='+units+',wave='+str(wave)+')\n\n')
  logging.info(' The Selected GaussClumps parameters can be found in the output files in the cats-txt directory generated by this program\n\n')

  ###############
  # STEP 2 - Get the smoothing Kernel's fwhm
  ###############
  
  #This will pick out the kernel FWHM in arcseconds - ASSUMING ONE OF THE STANDARD KERNELS IS USED
  
  kern_fwhm   = float(kern_name.split('.sdf')[0].split('_')[-1])
  
  ###############
  # STEP 3 - Define our conversion factor to Jy per beam
  ###############
  
  # Next we want to define our conversion factor from whatever units are supplied to Jy per beam
  
  #For mJy/arcsec^2 -> Jy/beam: arseconds per beam = (1.133 * beam_fwhm^2), so jypbm_conv = (1.133*beam_fwhm^2)/1000.0
  
  if units=='mjya2':
    jypbm_conv  = (1.133*beam_fwhm**2.0)/1000.0 #mJy/arcsec^2 -> Jy/beam
  
  #For pW -> Jy/beam, 850 microns: [2.34 Jy/pW/arcsec^2] * (1.133 * beam_fwhm^2) 
  
  #For pW -> Jy/beam, 450 microns: [4.71 Jy/pW/arcsec^2] * (1.133 * beam_fwhm^2)
  
  if np.logical_and(units=='pw',wave==850):
    jypbm_conv=2.34*(1.133*beam_fwhm**2.0) #pW -> Jy/beam 850 microns!
  
  if np.logical_and(units=='pw',wave==450):
    jypbm_conv=4.71*(1.133*beam_fwhm**2.0) #pW -> Jy/beam 450 microns!
  
  # Finally, if the maps are in Jyperbeam - no conversion is necessary
  
  if units=='jybm':
    jypbm_conv=1.0
  
  ###############
  # STEP 4 - Run the pipeline
  ###############
  
  filenumber  = 0
 
  #First, open a text file so we can save the calibration results (offsets and peak/radius calibration)
  calib_results = open('./calibration_results.txt', 'w')
  calib_results.write('PONG\t|\tDate\t|\tN Matches\t|\tN Survived Cull\t|\tAvg X_off\t|\tAvg Y_off\t|\tAvg Peak Ratio\t|\tAvg Radius Ratio\t|\tAvg X_off error\t|\tAvg Y_off error\t|\tAvg Peak Ratio error\t|\tAvg Radius Ratio error\t|\n')
  calib_results.write('-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n')

  #Now, run the pipeline in a loop over all the given images:
 
  for eachfile in img_names:
    logging.info('Beginning File: '+eachfile+'\n\n') 
    #Keep track of which file we are on
    filenumber+=1
    obsdate=eachfile.split('_'+str(int(wave)))[0].split('_')[-1]

    print('\n\nFile number: '+str(int(filenumber))+' out of '+str(len(img_names))+'\n')
    print('#################################')
    print('#################################\n\n')
  
    #Crop and smooth the image
    print('\nCropping and Smoothing the file...\n')
    logging.info(' Cropping and Smoothing the file...')
    start_time=time.time()
  
    prepare_image(eachfile, kern_name, kern_fwhm, jypbm_conv=jypbm_conv,beam_fwhm=beam_fwhm, crop_radius=crop_radius, crop_method=crop_method)
  
    end_time=time.time()
    print('\nCropping and Smoothing finished in '+str(round(end_time-start_time,2))+' Seconds\n')
    logging.info('Cropping and Smoothing finished in '+str(round(end_time-start_time,2))+' Seconds \n\n')

    #Identify the sources and produce Gaussclump catalogs
    print('\nRunning GaussClumps...\n')
    logging.info(' Running GaussClumps...')
    start_time=time.time()  
  
    run_gaussclumps(eachfile[:-4]+'_crop_smooth_jypbm.sdf', param_file)
  
    end_time=time.time()
    print('\nRunning GaussClumps finished in '+str(round(end_time-start_time,2))+' Seconds\n')
    logging.info('Running GaussClumps finished in '+str(round(end_time-start_time,2))+' Seconds \n\n')

    #Save the catalogue name that was just produced. If this is the first file, use it as the reference catalogue
    if filenumber==1:
      ref_name=eachfile[:-4]+'_crop_smooth_jypbm_log.FIT'
    cat_name=eachfile[:-4]+'_crop_smooth_jypbm_log.FIT'
  
    #Find the offsets/peak calibration with respect to the reference catalogue
    print('\nMatching Sources to the reference catalogue and performing the cull...\n')
    logging.info(' Matching Sources and performing the cull (cutoff set to '+str(cutoff)+' arcseconds)...')
    start_time=time.time()    
  
    calibresults=source_match(cat_name, ref_name, minpeak=minpeak, maxrad=maxrad, maxsep=maxsep, cutoff=cutoff)
   
    logging.info(' '+str(calibresults[3][0])+' sources had matches to the reference catalogue.....')    
    logging.info(' '+str(calibresults[2][0])+' of those matched sources survived the cull.....')
    #Add to the calibration results text file
    calib_results.write(str(filenumber)+'\t|\t'+obsdate+'\t|\t'+str(calibresults[3][0])+'\t|\t'+str(calibresults[2][0])+'\t|\t'+str(round(calibresults[0][0],4))+'\t|\t'+str(round(calibresults[0][1],4))+'\t|\t'+str(round(calibresults[0][2],4))+'\t|\t'+str(round(calibresults[0][3],4))+'\t|\t'+str(round(calibresults[1][0],4))+'\t|\t'+str(round(calibresults[1][1],4))+'\t|\t'+str(round(calibresults[1][2],4))+'\t|\t'+str(round(calibresults[1][3],4))+'\t|\n')

    end_time=time.time()
    if calibresults[2][0]==0:
      logging.warning(' THERE WERE NO SOURCES THAT SURVIVED THE CULL!\n\n')
    if calibresults[2][0]==1:
      logging.warning(' THERE WAS ONLY ONE SOURCE THAT SURVIVED THE CULL!\n\n')
    if calibresults[2][0]==2:
      logging.warning(' THERE WERE ONLY TWO SOURCES THAT SURVIVED THE CULL\n\n!')
    print('\nMatching Sources and culling finished in '+str(round(end_time-start_time,2))+' Seconds\n')
    logging.info(' Matching Sources and culling finished in '+str(round(end_time-start_time,2))+' Seconds\n\n')

  #Create a directory with today's date and clean up all the output files 
  print('\nCleaning up...\n')
  
  calib_results.close()

  os.system('mkdir TC-'+str(date))
  os.system('mkdir TC-'+str(date)+'/cats-fits')
  os.system('mkdir TC-'+str(date)+'/cats-txt')
  os.system('mkdir TC-'+str(date)+'/clumpmaps')
  os.system('mkdir TC-'+str(date)+'/cropped-smoothed-images/')
  os.system('mkdir TC-'+str(date)+'/calib-results-txt/')
  os.system('mv *log.FIT TC-'+str(date)+'/cats-fits/')
  os.system('mv *log.txt TC-'+str(date)+'/cats-txt/')
  os.system('mv *clumps.sdf TC-'+str(date)+'/clumpmaps/')
  os.system('mv *_jypbm.* TC-'+str(date)+'/cropped-smoothed-images/')
  os.system('mv calibration_results.txt TC-'+str(date)+'/calib-results-txt/')
  os.system('rm -f *crop.sdf')
  os.system('rm -f *crop_smooth.sdf')
  os.system('rm -f crop.ini')
  os.system('rm -f findclumpscript.sh')
  os.system('rm -f disp.dat')
  os.system('rm -f log.group')
  os.system('rm -f rules.badobs')
  os.system('rm -rf adam*')
  print('\n')
  
  final_time=time.time()
  
  print('\n\nProgram Completed Successfully in '+str(round(final_time-initial_time,2))+' Seconds\n\n')
  logging.info(' Program Completed Successfully in '+str(round(final_time-initial_time,2))+' Seconds\n\n')
  os.system('mv TCpipeline'+str(date)+'.log TC-'+str(date))
